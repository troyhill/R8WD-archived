---
title: ""
editor: 
  mode: source
# format: docx
# always_allow_html: yes
format:
  html:
    embed-resources: true # required for html images
    smooth-scroll: true
    theme: cosmo
    fontcolor: black
    toc: true
    toc-location: left
    toc-title: Table of Contents
    toc-depth: 3
---
    
```{r}
#| include: false
### make sure these are added as package dependencies
### consider using chapter format: https://stackoverflow.com/questions/72544775/passing-data-from-one-qmd-file-to-another-in-a-quarto-book-template
### or includes: https://quarto.org/docs/authoring/includes.html
library(ggplot2)
library(downloadthis)
library(plyr)
library(gt)
library(dataRetrieval)
library(webshot2)
library(htmlwidgets)
library(R8WD)

Tribal_org    <- c('SRSTEPA')  # c("WYDEQ_WQX", "WYDEQ_WATERSHED")
start_date    <- '01-01-2015'
end_date      <- '12-31-2022'
params_to_use <- c(1:length(params$params))
field_only    <- TRUE # if FALSE, lab blanks/reps are included in tables 1 and 2.
```

```{r}
#| echo: false
#| output: false
#| include: false

tribeData2 <- getWQP(
       organization       = Tribal_org,
       characteristicName = params$params[params_to_use],
       startDate          = start_date,
       endDate            = end_date,
       multiplier         = 0.5)

### preserve original CharacteristicName
tribeData2$CharacteristicName_original <- tribeData2$CharacteristicName

### homogenize parameter names
tribeData2$CharacteristicName <- params$new_param[match(tribeData2$CharacteristicName, params$params)]
### homogenize organization names.
### all information is interpreted as coming from a single organization
if (length(unique(tribeData2$OrganizationIdentifier) > 1)) {
  ### identify most abundant names and convert all to those
  tribeData2$OrganizationFormalName <- names(which.max(table(tribeData2$OrganizationFormalName)))
  tribeData2$OrganizationIdentifier <- names(which.max(table(tribeData2$OrganizationIdentifier)))
}

allSummary <- summarizeQC(data = tribeData2)

### identify parameters collected on sondes (no expectation of blank QC data)
sonde_parameters <- c('DO', 'pH', 'Temperature', 'Turbidity', 'Specific conductivity', 'Conductivity')
included_params <- paste0(unique(tribeData2$CharacteristicName), collapse = ', ')
included_params <- sub(",([^,]*)$",", and\\1", x = included_params)

params_not_found <- unique(params$new_param[params_to_use])[!(unique(params$new_param[params_to_use]) %in% unique(tribeData2$CharacteristicName))]
if (length(params_not_found) == 0) {
  params_not_found_message <- "All core parameters sought for this report were available in the organization's WQP data." 
} else if (length(params_not_found) == 1) {
  params_not_found_message <- paste0('**The only core parameter sought for this report that was** ***not*** **available was ', params_not_found, '. EPA recommends that data for all core parameters are collected and uploaded to WQP.**')
} else {
  params_not_found <- paste0(params_not_found, collapse = ', ')
  params_not_found <- sub(",([^,]*)$",", and\\1", x = params_not_found)
  params_not_found_message <- paste0('**The core parameters sought for this report that were** ***not*** **available were ', params_not_found, '. EPA recommends that data for all core parameters are collected and uploaded to WQP.**')
}
```


```{r}
#| include: false
tribal_logo_filename <- list.files(path = file.path(system.file('extdata', package = 'R8WD'), 'seals'), pattern = paste0('^', Tribal_org))
if (length(tribal_logo_filename) == 0) {
  img_path <- file.path(system.file('extdata', package = 'R8WD'), 'seals', 'epa_seal.png') # have two EPA logos if there's no organization-specific logo
} else {
  img_path <- file.path(system.file('extdata', package = 'R8WD'), 'seals', tribal_logo_filename[1])
}

# img_path_epa <- system.file('extdata/seals', 'epa_seal.png', package = 'R8WD')
img_path_epa <- file.path(system.file('extdata', package = 'R8WD'), 'seals', 'epa_seal.png')
```


## Quality Control Data Assessment Report for the `r allSummary$data$OrganizationFormalName[1]` CWA106 Program

#### Draft report generated on `r format(Sys.Date(), '%d %b %Y')` for internal use only

::: {layout="[[25,-30, 25],]"}
![](`r img_path_epa`)

![](`r img_path`)
:::


## Disclaimer

The information in this report is provided on an "as is" basis and its use does not imply endorsement or verification by United States Environmental Protection Agency (EPA). These data and any interpretations do not necessarily represent the EPAâ€™s official position or viewpoint, expressed or implied. EPA strongly recommends careful attention be paid to metadata files associated with these data to better understand limitations, restrictions or intended use. The U.S. EPA shall not be held liable for improper or incorrect use of the data. Any reference to specific commercial products, processes, or services by service mark, trademark, manufacturer, or otherwise, does not constitute or imply their endorsement, recommendation or favoring by EPA. The EPA seal and logo shall not be used in any manner to imply endorsement of any commercial product or activity by EPA or the United States Government.


## Introduction

EPA-funded water quality monitoring programs should enable data-driven decisions about the protection and conservation of water resources. If water quality data are to be useful for decision-making, they must be of known and documented quality. The limitations of a dataset must be clear to current and future users who may have to defend their decisions or conduct new analyses requiring independent evaluation of previously-collected data. Quality control data are essential determinants of whether a dataset can generate meaningful insights.


### The Dataset

```{r}
#| echo: false
obs_dist <- as.numeric(table(allSummary$data$MonitoringLocationIdentifier[!is.na(allSummary$data$ResultMeasureValue)]))

newDat      <- allSummary$data[!is.na(allSummary$data$ResultMeasureValue), ]
newDat$year <- as.numeric(substr(newDat$ActivityStartDate, 1, 4))
params_per_site <- ddply(newDat[, c('CharacteristicName', 'ResultMeasureValue', 'ActivityStartDate', 'MonitoringLocationIdentifier', 'year')], 
                         c('MonitoringLocationIdentifier', 'year'), summarise, 
                         `Unique parameters per site` = length(unique(CharacteristicName)), 
                         `Sampling events per site`   = length(unique(ActivityStartDate)),
                         `Data points per site`       = sum(!is.na(ResultMeasureValue)))
obs_per_yr <- ddply(newDat[, c('CharacteristicName', 'ResultMeasureValue', 'ActivityStartDate', 'MonitoringLocationIdentifier', 'year')], 
                         c('year'), summarise, 
                    `Parameters measured`  = length(unique(CharacteristicName)), 
                    `Sites`                = length(unique(MonitoringLocationIdentifier)), 
                    `Sampling events`      = length(unique(ActivityStartDate)),
                    `Data points per year` = sum(!is.na(ResultMeasureValue)))
obs_per_yr$label_text    <- paste0(obs_per_yr$Sites)
obs_per_yr$label_text[1] <- paste0('Sites sampled =\n', obs_per_yr$label_text[1])
label_location <- as.numeric(quantile(x = params_per_site$`Data points per site`, probs = 0.98, na.rm = TRUE))

# allSummary$data[grepl(x = allSummary$data$MonitoringLocationIdentifier, pattern =
# 'SRSTEPA-SW-FD-2017-01'), c('CharacteristicName', 'ResultMeasureValue', 'ActivityStartDate', 'MonitoringLocationIdentifier')]
param_plot <- ggplot(params_per_site, aes(y = `Data points per site`, x = year, group = year)) + geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.15, alpha = 0.35) + theme_bw() + xlab('') +
  scale_y_continuous(limits = c(0, max(params_per_site$`Data points per site`, na.rm = TRUE)*1.1)) +
  scale_x_continuous(breaks = seq(1800, 2500, 1), minor_breaks = seq(1800, 2500, 1)) + 
  geom_text(data = obs_per_yr,
    aes(x = year, y = label_location,label = label_text),
    vjust = -0.5, size = 4, stat = "identity"
  ) 


### repeat first year's data if there's only one year. 
### TODO: modify this behavior, maybe form the whole sentence here
nval <- 1
if (nrow(obs_per_yr) > 1) {
  nval <- 2
}
min_obs_per_yr  <- min(obs_per_yr$`Data points per year`)
min_obs_yr      <- obs_per_yr$year[which.min(obs_per_yr$`Data points per year`)]
min_obs_per_yr2 <- head(tail(sort(obs_per_yr$`Data points per year`, decreasing = T), nval),1)
min_obs_yr2     <- obs_per_yr$year[which(obs_per_yr$`Data points per year` == head(tail(sort(obs_per_yr$`Data points per year`, decreasing = T), nval),1))]
max_obs_per_yr  <- max(obs_per_yr$`Data points per year`)
max_obs_yr      <- obs_per_yr$year[which.max(obs_per_yr$`Data points per year`)]

min_years_message <- paste0(x = range(suppressWarnings(as.numeric(unique(na.omit(format(allSummary$data$ActivityStartDate, '%Y')))))), collapse = ' and ')

```

This report evaluates quality control data associated with a set of core physical and chemical measures common among CWA106 monitoring programs. Data used in this report were queried from the Water Quality Portal ([WQP](https://www.waterqualitydata.us/){.external target="_blank"}), which collates data from a variety of sources including the EPA's Water Quality Exchange (WQX) Data Warehouse. 

Core parameters available in data from the `r allSummary$data$OrganizationFormalName[1]` CWA106 Program included `r included_params`. `r params_not_found_message`

The data in this report draw from  `r sum(!is.na(unique(allSummary$data$MonitoringLocationIdentifier)))` sampling locations (Fig. 1). These locations had between `r round(min(obs_dist))` and `r round(max(obs_dist))` (median: `r round(median(obs_dist))`) total data points collected during the `r  suppressWarnings(length(unique(na.omit(format(allSummary$data$ActivityStartDate, '%Y')))))` years of sampling activity reported between `r min_years_message`. 

The volume of data generated by this project varied over time, as shown in Figure 2. The least data was collected in `r min_obs_yr` (`r min_obs_per_yr` total observations across all sites and sampling dates) and `r  min_obs_yr2` (`r min_obs_per_yr2` observations). The most intense year of data collection was `r max_obs_yr` (`r max_obs_per_yr` observations). 


::: {.content-hidden when-format="html"}
```{r}
#| echo: false
# if (grepl(x = output_type, pattern = 'html')) {
#   create_map(tribeData2)
# } else if (grepl(x = output_type, pattern = 'docx')) {
  ### word-compatible figure
  mapfile <- tempfile(fileext = '.html') # file.path(getwd(), 'test.html') #tempfile(fileext = '.png')
  mapfile_png <- tempfile(fileext = '.png')
  # grDevices::png(mapfile)
  # leaflet::leaflet(options = leaflet::leafletOptions(zoomSnap = 0.25, zoomDelta=0.25))
  m <- create_map(tribeData2)
  m <- leaflet::fitBounds(m, lng1 = -116, lat1 = 36.6, lng2 = -95.8, lat2 = 49.4)
  m$height <- 1400
  m$width  <- 1800
  # grDevices::dev.off()
  # webshot2::webshot('temp.html', file = mapfile, cliprect="viewport")
  htmlwidgets::saveWidget(m, mapfile, selfcontained = TRUE)
  # mapview::mapshot(m, file = mapfile,
  #         remove_controls = c("homeButton", "layersControl"))
  webshot2::webshot(mapfile, file = mapfile_png, cliprect="viewport")
# }
```
:::


::: {.content-hidden when-format="docx"}
```{r}
#| echo: false
create_map(tribeData2)
```
:::
Figure 1. Map of sampling locations included in this report.




```{r}
#| echo: false
#| fig-width: 8
#| fig-cap: Figure 2. Boxplots showing the distribution of observations collected at each sampling site and year. Jittered points show the underlying data; each point indicates the number of observations generated at an individual site in a given year. The number of sites sampled in each year is indicated.
param_plot
```


### Data Preparation

In preparing data for analysis, non-detects (values below detection limits) were treated numerically as half of the reported detection limit (e.g., a value reported as \'<1 mg`r "\U22C5"`L^-1^\' would be treated as \'0.5 mg`r "\U22C5"`L^-1^\'). Estimated values above a maximum value were treated as equivalent to the maximum known value (e.g., a value reported as \'>250 mg`r "\U22C5"`L^-1^\' would be treated as \'250 mg`r "\U22C5"`L^-1^\'). If a detection limit included a less-than symbol it was replaced by the stated upper bound (e.g., an MDL appearing as \'<1 mg`r "\U22C5"`L^-1^\' would be treated as \'1 mg`r "\U22C5"`L^-1^\'). Data users should consult the raw data available from WQP to determine if any of these issues apply in the data described in this report. Future data users are encouraged to address censored values in ways that are appropriate for their motivating questions and in consultation with relevant literature (including EPA's [QA/G-9 Guidance For Data Quality Assessment](https://www.epa.gov/sites/default/files/2015-06/documents/g9-final.pdf){.external target="_blank"}). 

Several other adjustments and assumptions were made prior to analysis. All pH data were converted from log-scale pH values to molar H^+^ concentrations ($[H^{+}] = 10^{-pH}$) before any analyses were performed, and then converted back ($pH = -log_{10}[H^{+}]$) to unitless pH values for visualization and reporting. The WQP characteristics 'Ammonia', 'Ammonia and ammonium', and 'Ammonia-nitrogen' were treated as interchangeably representing NH~3~-N levels. Similarly, WQP data for the characteristics 'Temperature' and 'Temperature, water' were treated as interchangeable measures of water temperature (air temperatures were assumed to be input as 'Temperature, air'). The WQP characteristics 'Nitrate' and 'Nitrate + Nitrite' were treated as distinct quantities for this report. The WQP characteristics used for total nitrogen (TN) and total phosphorus (TP) were 'Total Nitrogen, mixed forms' and 'Total Phosphorus, mixed forms,' respectively.

<!-- NO~3~^-^-N methods convert NO~2~^-^-N -->


## Blank Performance


### Context

Blanks are analyte-free media used to detect contamination during some portion of a sampling activity. Blanks serve a critical quality control function in any project by allowing analysts to quantify the extent to which apparent signal in project data could be noise introduced by contamination. There are a variety of blank types (examples include trip, equipment, sampler, and filter blanks) designed to isolate contamination occurring during different aspects of a project. The focus of this report is on field and lab blanks.

Field blanks should be treated as if they are routine field samples. For example, a bottle of analyte-free water may be brought to a sampling site, poured into a sample bottle following the project's sample collection procedures, and then treated exactly the same as a routine field sample (stored in the same cooler, processed for the same analytes by the same laboratory). Field blanks measure contamination that occurs anywhere in the project from sample collection all the way through to sample analysis. If field blanks remain analyte-free upon analysis, they provide confidence that contamination has been minimized throughout the entire project workflow. If field blanks indicate contamination is occurring, other blank types can be useful in identifying the contamination source by isolating specific aspects of a project workflow.

Laboratory blanks are a quality control measure that isolates contamination introduced during laboratory analysis. Lab blanks are analyte-free media introduced into the project workflow at the laboratory and processed as if they were samples from that point forward. Lab blanks capture contamination from reagents, sample storage and handling protocols, and instrument carryover or other issues arising during instrument runs. These quality control samples provide insight into a laboratory's ability to generate data useful for decision-making.

Evaluation of blank performance is fundamentally simple; if an analyte is detected in a blank, the analyst should be concerned about contamination. When blank contamination is observed, project staff should review their sample collection and handling standard operating procedures (SOPs) to ensure that approaches to avoiding contamination are clearly and comprehensively documented. Staff training can help ensure that SOPs are implemented consistently by all project participants. SOPs should be updated as needed to provide clearer guidance on approaches to avoiding contamination (e.g., clarifying that gloves should be changed prior to collecting each sample or how bottle caps should be handled during sampling). Even projects without evidence of contamination should be vigilant, routinely training staff and critically reviewing SOPs.

As a general guideline, field blanks should be collected at a rate of at least one blank per 10 samples or one blank per sampling day, whichever results in more quality control data. Laboratory blanks should also generally be run at least once every 10 samples. Project staff should consider increasing blank collection rates as appropriate for their project. More frequent blanks may be warranted where results are likely to be consequential, litigated, or for analytes with low action levels or those that are prone to contamination (e.g., studies measuring per- and polyfluoroalkyl  substances).


### Summary of Blank Data


```{r}
#| echo: false
#| message: false
#| warning: false

### get total samples per analyte to calculate blank ratio
tot_samples <- plyr::ddply(allSummary$data, c('CharacteristicName'), plyr::summarise,
                           `Total observations`            = length(na.omit(ResultMeasureValue))
  )

### blanks aren't expected for sonde parameters - could implement this better
analytes    <- tot_samples$CharacteristicName[which(!tot_samples$CharacteristicName %in% sonde_parameters)]
if (length(analytes) == 0) {
    ### table should still exist if no non-sonde data is collected
    analytes    <- NA
  }
blank_table <- expand.grid('Sample Type' = c('Field Blank', 'Lab Blank'), 'Analyte' = analytes)
blank_table <- blank_table[order(blank_table$`Sample Type`, blank_table$Analyte), ]

if (nrow(allSummary$blank_proc) == 0) {
  blank_table$`Blanks (no.)`                 <- 0
  blank_table$`Years with blanks`            <- 0
  blank_table$`Blanks above MDL (no.)`       <- NA
  blank_table$`Blanks above MDL (%)`         <- NA
  blank_table$`Are replicates >10% of samples?`        <- "\u274C"
  blank_table$`Are <10% of replicates high-variation?` <- "\u274C"

} else {
  blank_int <- plyr::ddply(allSummary$blank_proc, c('ActivityTypeCode', 'CharacteristicName'), plyr::summarise,
                           `Blanks (no.)`            = length(na.omit(year)),
                           `Years with blanks` = length(na.omit(unique(year))),
                           `Blanks above MDL (no.)`  = sum(exceedMDL, na.rm = TRUE),
                           `pct_above_MDL`           = sum(exceedMDL, na.rm = TRUE)/length(na.omit(exceedMDL))*100,
                           `Blanks above MDL (%)`    = paste0(round(pct_above_MDL,0), '%')
  )
  blank_int$`Sample Type` <- sapply(X = strsplit(blank_int$ActivityTypeCode, '-'), FUN = '[[', 2)
  blank_int$Analyte       <- blank_int$CharacteristicName
  # using plyr::rbind.fill preserves possible sonde analytes that have data points labeled as blanks. join_all would eliminate them
  blank_int        <- plyr::join_all(list(blank_table, blank_int[, c(3:ncol(blank_int))]), type = 'full') 
  blank_int        <- blank_int[order(blank_int$`Sample Type`, blank_int$Analyte), ]
  blank_int$`Total observations` <- tot_samples$`Total observations`[ match(blank_int$Analyte, tot_samples$CharacteristicName)]
  blank_freq           <- blank_int$`Blanks (no.)` / blank_int$`Total observations`*100
  blank_freq[is.na(blank_freq)] <- 0
  blank_int$`Blank collection rate`    <- paste0(round(blank_freq, 1), '%')
  blank_int$`Blanks (no.)`[is.na(blank_int$`Blanks (no.)`)] <- 0
  blank_int$`Years with blanks`[is.na(blank_int$`Years with blanks`)] <- 0

# blank_table             <- blank_int[, c(10, 11, 3:5, 7, 9)] # old 
blank_table             <- blank_int[, c(1:5, 7, 9)]
blank_table$`Is blank collection rate >10%?`  <- ifelse(blank_freq >= 10.0, "\u2705", "\u274C")
blank_table$`Are <5% of blanks contaminated?` <- ifelse(blank_int$pct_above_MDL <= 5.0, "\u2705", "\u274C")
# blank_table$`Are <5% of blanks contaminated?`[is.na(blank_table$`Are <5% of blanks contaminated?`)] <- "\u274C"
}
if (field_only) {
  blank_table <- blank_table[grep(x = blank_table$`Sample Type`, pattern = 'Field'), ]
}
```


```{r}
#| echo: false
#| warning: false

if (nrow(allSummary$blank_proc) == 0) {
 blank_plot <- ggplot()
} else {
allSummary$blank_proc$date <- as.POSIXct(allSummary$blank_proc$ActivityStartDate, format = '%Y-%m-%d')
blank_perf  <- allSummary$blank_proc[grepl(x = tolower(allSummary$blank_proc$ActivityTypeCode), pattern = 'field blank'), ]
blank_perf$`Performance target met?` <- ifelse(blank_perf$ResultMeasureValue > blank_perf$DetectionQuantitationLimitMeasure.MeasureValue, 'No', 'Yes')
blank_perf$`Performance target met?`[is.na(blank_perf$`Performance target met?`)] <- 'No MDL reported'
blank_perf$`Performance target met?` <- ordered(x = blank_perf$`Performance target met?`, levels = c('No', 'Yes', 'No MDL reported'))

# blank_plot1 <- ggplot(blank_perf, aes(x = date, y = ResultMeasureValue)) +
#   geom_line(linetype = 2) + geom_point() + 
#   facet_wrap(. ~ CharacteristicName, scales = 'free_y') + theme_bw() + theme(plot.margin = margin(r = 40, unit = "pt")) +
#   geom_line(aes(y = DetectionQuantitationLimitMeasure.MeasureValue, x = date), col = 'red', linetype = 1) +
#   geom_point(aes(y = DetectionQuantitationLimitMeasure.MeasureValue, x = date), col = 'red', size = 0.5) +
#   labs(y = 'Field blank level', x = '')
blank_plot <- ggplot(blank_perf, aes(x = date, y = ResultMeasureValue)) +
  geom_line(linetype = 2) + 
  geom_point(aes(fill = `Performance target met?`), pch = 21, size = 3) + scale_fill_manual(values = c("red", "green", "gray")) +
  theme_bw() + facet_wrap(. ~ CharacteristicName, scales = 'free_y') + theme_bw() + theme(plot.margin = margin(r = 40, unit = "pt")) +
  labs(y = 'Field blank level', x = '') + theme(legend.position='bottom')
}



```


```{r}
#| echo: false
#| warning: false
#| message: false
tmp <- table(allSummary$blank_proc$ActivityTypeCode[!is.na(allSummary$blank_proc$ResultMeasureValue)])

### if TN is always a calculated value, exclude it from total samples
if (all((length(unique(allSummary$data[allSummary$data$CharacteristicName == 'TN', 'ResultAnalyticalMethod.MethodIdentifier'])) == 1) & (unique(allSummary$data[allSummary$data$CharacteristicName == 'TN', 'ResultAnalyticalMethod.MethodIdentifier']) == 'Calculated'))) {
  sonde_parameters <- c(sonde_parameters, 'TN')
}

number_of_lab_blanks <- ifelse(any(grepl(x = names(tmp), pattern = 'Lab')), sum(tmp[grepl(x = names(tmp), pattern = 'Lab')]), 0)
number_of_field_blanks <- ifelse(any(grepl(x = names(tmp), pattern = 'Field')), sum(tmp[grepl(x = names(tmp), pattern = 'Field')]), 0)
no_years <- suppressWarnings(length(unique(na.omit(format(allSummary$data$ActivityStartDate, '%Y')))))
### number of samples, excluding sonde data
no_samples <- sum(!is.na(allSummary$data$ResultMeasureValue[!(allSummary$data$CharacteristicName %in% sonde_parameters)]))


### correct for cases where no blank data are reported
if (length(number_of_lab_blanks) == 0)   number_of_lab_blanks   <- 0
if (length(number_of_field_blanks) == 0) number_of_field_blanks <- 0 
if (nrow(allSummary$blank_summary) == 0)  {
  number_field_blank_detects  <- NA
  percent_field_blank_detects <- NA
} else {
  number_field_blank_detects <- sum(allSummary$blank_summary$above_MDL[grep(x =   allSummary$blank_summary$ActivityTypeCode, pattern = 'Field Blank')], na.rm = TRUE)
  
  percent_field_blank_detects <- round(sum(allSummary$blank_summary$above_MDL[grep(x = allSummary$blank_summary$ActivityTypeCode, pattern = 'Field Blank')], na.rm = TRUE) / sum(allSummary$blank_summary$n[grep(x = allSummary$blank_summary$ActivityTypeCode, pattern = 'Field Blank')], na.rm = TRUE), 3)*100
  }



### identify parameters without QC data (exclude sonde measurements)
parameters_without_blanks <- unique(allSummary$data$CharacteristicName)[!(unique(allSummary$data$CharacteristicName) %in% c(unique(allSummary$blank_summary$CharacteristicName), sonde_parameters))]
if(length(parameters_without_blanks) < 1) {
 parameter_blank_message <- 'All of the laboratory parameters included in this report had some blank data.'
} else {
  parameter_blank_message <- paste0('Laboratory analytes entirely lacking blank data included ', paste0(parameters_without_blanks, collapse = ', '),'.')
}


### check for parameter-years without blanks
blankDat                 <- allSummary$blank_proc
param_yrs_wo_blank <- plyr::ddply(blankDat[, c('CharacteristicName', 'ResultMeasureValue', 'year')], 
                         c('CharacteristicName', 'year'), plyr::summarise, 
                         number_of_blanks       = sum(!is.na(ResultMeasureValue)))

### which of these year-parameter combos have data collected?
tmpDat <- allSummary$data
tmpDat$year <- as.numeric(substr(tmpDat$ActivityStartDate, 1, 4))
blanks_expected <- plyr::ddply(tmpDat[, c('CharacteristicName', 'ResultMeasureValue', 'year')], 
                         c('CharacteristicName', 'year'), plyr::summarise, 
                         number_of_obs       = sum(!is.na(ResultMeasureValue)))
if (nrow(param_yrs_wo_blank) == 0) {
  blanks_expected$number_of_blanks <- NA
} else {
  blanks_expected <- join_all(list(blanks_expected, param_yrs_wo_blank))
}
blanks_expected$number_of_blanks[is.na(blanks_expected$number_of_blanks)] <- 0
blanks_expected$ratio <- blanks_expected$number_of_blanks / blanks_expected$number_of_obs * 100
blanks_expected$`Collection rate target met?` <- ifelse(blanks_expected$ratio < 10, 'No', 'Yes')

blank_ratio_plot <- ggplot(data = blanks_expected[!(blanks_expected$CharacteristicName %in% sonde_parameters) & !is.na(blanks_expected$ratio), ], aes(x = year, y = ratio)) + 
  geom_point(aes(fill = `Collection rate target met?`), pch = 21, size = 3)+ 
  scale_x_continuous(breaks = seq(1800, 2500, 1), minor_breaks = seq(1800, 2500, 1)) + 
  scale_fill_manual(values = c("red", "green")) + theme_bw() + facet_wrap(. ~ CharacteristicName) + geom_hline(yintercept = 10, linetype = 2) +
  scale_y_continuous(labels = function(x) paste0(x, "%"))  + ylab('Field blank collection rate') + xlab('') + geom_line(linetype = 3, col = 'gray60') + 
  theme(legend.position='bottom')

### is there a trend in blank collection rates over time:
blank_lm <- summary(lm(ratio ~ year, data = blanks_expected[!(blanks_expected$CharacteristicName %in% sonde_parameters) & is.finite(blanks_expected$ratio), ]))
blank_rsq   <- blank_lm$r.squared # r2 for time variable
blank_pval  <- blank_lm$coefficients[8] # p-value for time variable
blank_slope <- blank_lm$coefficients[2] # slope over time

if (is.na(blank_pval)) {
  blank_collection_trend_message <- '' 
} else if (blank_pval > 0.05) {
  blank_collection_trend_message <- paste0('Across all available laboratory analytes (Fig. 3), blank collection frequencies do not show any trend over time (linear model; P>0.05).')
} else if (blank_pval < 0.05) {
  blank_collection_trend_message <- paste0('Across all available laboratory analytes, blank collection frequencies show a significant ', ifelse(blank_slope < 0, "downward", "upward"), ' trend over time (linear model; P<0.05, r^2^ = ', round(blank_rsq, 2), ').')
  if (blank_slope < 0) {
    blank_collection_trend_message <- paste0(blank_collection_trend_message, ' Declining blank collection rates are deeply concerning. The project should immediately raise blank collection rates to at least 10% of the samples collected. Figure 3 can be used to identify parameters needing better blank coverage (those shown as red points).')
  }
   if (blank_slope > 0) {
    blank_collection_trend_message <- paste0(blank_collection_trend_message, ' Rising blank collection rates are very encouraging and the effort directed at this quality control metric is commended.')
  }

}
  
# obs_per_yr <- ddply(newDat[, c('CharacteristicName', 'ResultMeasureValue', 'ActivityStartDate', 'MonitoringLocationIdentifier', 'year')], 
#                          c('year'), summarise, 
#                     `Parameters measured` = length(unique(CharacteristicName)), 
#                     `Sites` = length(unique(MonitoringLocationIdentifier)), 
#                     `Sampling events`   = length(unique(ActivityStartDate)),
#                          `Data points per year`       = sum(!is.na(ResultMeasureValue)))


### identify parameter-years without QC data 
years_with_blanks    <- as.numeric(unique(allSummary$blank_summary$year))
years_with_data      <- sort(as.numeric(na.omit(unique(substr(allSummary$data$ActivityStartDateTime, 1, 4)))))
years_without_blanks <- years_with_data[!(years_with_data %in% years_with_blanks)]

if(length(years_without_blanks) < 1) {
 year_blank_message <- 'Some blank data was reported in every year during the period of record covered by this report.' 
} else {
  year_blank_message <- paste0('Blank data was completely missing from ', sub(",([^,]*)$",", and\\1", x = paste0(years_without_blanks, collapse = ', ')),'.')
}
if (any(blanks_expected[!(blanks_expected$CharacteristicName %in% sonde_parameters), ]$number_of_blanks == 0)) {
  # year_blank_message
  tst <- blanks_expected[!(blanks_expected$CharacteristicName %in% sonde_parameters), ][
   which(blanks_expected[!(blanks_expected$CharacteristicName %in% sonde_parameters), ]$number_of_blanks == 0), c('CharacteristicName', 'year')]
  fragments <- apply(X = tst, MARGIN = 1, FUN = paste0, collapse = ' in ')
  fragments <- sub(",([^,]*)$",", and\\1", x = paste0(fragments, collapse = ', '))
  year_blank_message <- paste0(year_blank_message, " ", sum(blanks_expected[!(blanks_expected$CharacteristicName %in% sonde_parameters), ]$number_of_blanks == 0), ' parameter-years had lab data without corresponding blank data (', fragments, '; see points with 0% collection rates in Figure 3). Quality control measures should always be collected when samples are collected.')
} else {
  ' Although not every lab parameter may be measured every year, every parameter-year combination that had data reported for this project also had some blank data reported.'
}

### check for sonde data that have blanks
blank_sonde_params       <- unique(blankDat$CharacteristicName)[which(unique(blankDat$CharacteristicName) %in% sonde_parameters)]
sonde_params_with_blanks <- sub(",([^,]*)$",", and\\1", x = paste0(blank_sonde_params, collapse = ', '))

MDL_check <- plyr::ddply(blankDat[blankDat$CharacteristicName %in% blank_sonde_params, ], c('CharacteristicName'), plyr::summarize, 
            all_NAs = all(is.na(DetectionQuantitationLimitMeasure.MeasureValue)))
if (any(MDL_check$all_NAs)) {
  sonde_params_with_blanks_but_no_MDLs <- sub(",([^,]*)$",", and\\1", paste0(x = MDL_check$CharacteristicName[MDL_check$all_NAs == TRUE], collapse = ', '))
  sonde_params_with_blanks_but_no_MDLs_message <- paste0(sonde_params_with_blanks_but_no_MDLs, ' also had no MDLs reported, suggesting possible mis-characterization of these samples as blanks.') 
} else {
  sonde_params_with_blanks_but_no_MDLs_message <- ' These possible sonde parameters did have corresponding MDLs, so they may have been correctly identified as blanks.'
}

if (length(sonde_params_with_blanks) > 0) {
  sonde_param_statement    <- paste0("The presence of blank data for ", sonde_params_with_blanks, " was concerning given that those data are likely to have been collected with sondes. ", sonde_params_with_blanks_but_no_MDLs_message, " Project staff are urged to confirm the accuracy of these data entries.")
}

overall_fieldBlank_rate  <- round(number_of_field_blanks / no_samples*100, 1)
overall_blank_collection <-  paste0("Across all years and relevant analytes, the project's field blank collection rate was ", overall_fieldBlank_rate, "%.")
if (overall_fieldBlank_rate < 10) {
  overall_blank_collection <- paste0(overall_blank_collection, " This collection rate is below this report's 10% target for collection rates. Project staff are encouraged to ensure that current blank collection rates are at least 10% of relevant samples, and to regularly report blank collection rates by parameter in project progress reports.")
} else {
  overall_blank_collection <- paste0(overall_blank_collection, " This collection rate satisfies this report's 10% target for collection rates.")
}

### check for blank data without MDLs and varying MDLs


```


The `r allSummary$data$OrganizationFormalName[1]` CWA106 project collected `r sum(allSummary$blank_summary$n, na.rm = TRUE)` field and lab blanks during the period of interest for this report. This total number is composed of `r number_of_field_blanks` field blanks and `r number_of_lab_blanks` laboratory blanks. Of the field blanks, `r number_field_blank_detects` (`r percent_field_blank_detects`%) had detectable analyte levels.

`r year_blank_message`

`r parameter_blank_message`

`r sonde_param_statement`

`r blank_collection_trend_message`



```{r}
#| echo: false
#| warning: false
#| fig-width: 8
#| fig-cap: Figure 3. Field blank collection rates for each analyte over time. Red-filled points indicate blank collection rates below the target 10% (dashed horizontal line); green-filled circles indicate parameter-years meeting the 10% target.
blank_ratio_plot
```


```{r}
#| echo: false
#| warning: false
#| fig-width: 8
#| fig-cap: Figure 4. Levels observed in field blanks for each analyte over time. Field blanks with undetectable levels satisfy this report's performance target and are shown as green points. Blanks with levels above the method detection limit (MDL) are shown in red. If no MDL was reported, blank data appear in gray.
blank_plot
```


```{r}
#| echo: false
#| fig-cap: Table 1. A summary of blank data for each analyte over the entire period of record covered by this report. Rightmost two columns assess whether the project's blank collection rates and blank performance meet target criteria (green checks) or not (red 'X' marks).

gt::tab_options(gt::gt(blank_table), table.font.size = 11)
# kableExtra::kable_styling(kableExtra::kbl(blank_table, row.names = FALSE), bootstrap_options = c("striped", "hover"), font_size = 9)
```



### Recommendations


```{r}
#| include: false
### recommendations based on blank data 
rec_list <- list()
if (number_of_lab_blanks == 0) {
  lab_blank_rec <- '**Laboratory blanks** were completely absent from data found in the Water Quality Portal. These data appear to have been either not collected or not input into WQP. More comprehensive collection and reporting of laboratory blanks for conducting meaningful assessments of data quality, identifying contamination, and making comparisons among data from different laboratories. Project staff are encouraged to ensure lab blank data are entered into WQP. Including lab blank performance in project progress reports is recommended as an effective way to track improvements in this quality metric.'
} else if (number_of_lab_blanks < 0.10*no_samples) {
  lab_blank_rec <- paste0('**Laboratory blanks** appear in the data reported to WQP, but represent just ', round(number_of_lab_blanks / no_samples*100), '% of all samples. Recommendations include ensuring that laboratory blanks are reported comprehensively and including laboratory blanks at a rate of at least 10% of lab samples. Including lab blank performance in project progress reports is recommended as an effective way to track improvements in this quality metric.')
} else if (number_of_lab_blanks >= 0.10*no_samples) {
  lab_blank_rec <- '**Laboratory blanks** represent at least 10% of all lab samples. Project Managers are commended for their high level of effort and reporting on this quality metric.'
}
rec_list$lab_blank <- lab_blank_rec


### field blanks
if (number_of_field_blanks == 0) {
  field_blank_rec <- '**Field blanks** were either not collected or not input into WQP. More comprehensive reporting of field blanks in WQX is critical for evaluating contamination and bias in the generated data. Including blank collection rates for each parameter in project progress reports would be an effective way to track improvement in this metric.'
} else if (number_of_field_blanks < 0.10*no_samples) {
  field_blank_rec <- paste0('**Field blanks** appear in the reported data at a rate of ', overall_fieldBlank_rate, '% of all relevant samples (excluding sonde data). Increasing the field blank collection rate to at least 10% is highly recommended. Improving collection and reporting of field blank data is critical to ensure that project data can be useful for decision-making. Including blank collection rates for each parameter in project progress reports would be an effective way to track improvement in this metric.')
} else if (number_of_field_blanks >= 0.10*no_samples) {
  field_blank_rec <- paste0('**Field blanks** represent ', overall_fieldBlank_rate, '% of all samples (excluding sonde data), above the target level of 10%. Project Managers are commended for their high level of effort and reporting on this quality metric.')
}
rec_list$field_blank <- field_blank_rec

### Inconsistent blank collection (over time and among parameters)
if (length(apply(X = tst, MARGIN = 1, FUN = paste0, collapse = ' in ')) > 0) {
  blank_collection_consistency_time <- paste0('**Field blank coverage:** Field blank data were collected inconsistently and were not present for all parameters in every year. Notably, ', length(apply(X = tst, MARGIN = 1, FUN = paste0, collapse = ' in ')), ' parameter-years lacked any field blank data. Blanks should be collected at least once per 10 samples for every parameter. Documenting blank collection rates in project progress reports is recommended as a way to track and improve blank coverage.')
} else {
  blank_collection_consistency_time <- paste0("**Field blank coverage:** Field blank data were collected very consistently, including some blank data for every parameters in every year. Although there may be room for improvement to hit the taget 10% rate for all parameters, the presence of these data commendable and demonstrates the project staff's strong commitment to quality control.")
}

# if ((length(parameters_without_blanks) == 0)) {
#   blank_collection_consistency_param <- '**Field blank collection by parameter:** Evaluating consistency in blank reporting across parameters, it is observed that the reported data include at least one blank for every laboratory analyte. Project managers should ensure that this comprehensive level of quality control data continues.'
# } else if ((length(parameters_without_blanks) > 0)) {
#   blank_collection_consistency_param <- '**Blank collection by parameter:** Blanks were not reported consistently across parameters, with some analytes having no blank data found in the Water Quality Portal. Project managers should ensure that every analyte has field and lab blank data reported for every year in which that analyte is measured.'
# }

### blank performance and possible sample handling issues
if(is.na(percent_field_blank_detects)) {
  blank_issues <- 'The absence of field blank data for core CWA106 parameters makes it impossible to evaluate bias in the dataset.'
} else if(percent_field_blank_detects <= 10) {
  blank_issues <- 'This is encouraging and indicates consistent attention to detail during sample collection and handling.'
} else {
  blank_issues <- 'This magnitude of contamination deserves further attention and effort to identify its causes. Increasing the blank collection rate and re-training staff are among the possible ways to reduce contamination during sample collection and handling.'
}

# ### simplify message if there's no blank data
# if (number_of_field_blanks == 0) {

rec_list$blank_freq_time  <- blank_collection_consistency_time
rec_list$blank_issues     <- paste0('**Blank performance:** Overall, ', percent_field_blank_detects, '% of blanks had evidence of contamination. ' , blank_issues, ' See Table 1 and Figure 3 for parameter-specific performance and to identify specific areas for improvement.')
```

-   `r rec_list$lab_blank`

-   `r rec_list$field_blank`

-   `r rec_list$blank_freq_time`

-   `r rec_list$blank_issues`



## Replicate Performance

### Context

<!-- `r sum(allSummary$blank_summary$Blanks, na.rm = TRUE)` lab and field blanks appeared in the dataset: `r number_of_lab_blanks` laboratory blanks and `r number_of_field_blanks` field blanks. Of the field blanks, `r number_field_blank_detects` (`r percent_field_blank_detects`%) had detectable analyte levels. -->

Replicates are a category of quality control measures that document how precise a procedure is. Field replicates are samples from the same location collected simultaneously in separate bottles, and then processed as if they were entirely separate samples. 

Field replicates are typically collected individually, rather than split from a single water sample, and unavoidably incorporate some level of natural variation. However, water bodies are unlikely to vary dramatically on time scales relevant to collection of field replicates. Poor replicate agreement is more likely attributable to inconsistencies in sample collection (e.g., collecting replicates from slightly different locations or depths in a stream, or disturbing sediment during sampling), sample handling, or other aspects of the sampling workflow. 

Importantly, field replicates go through the entire sample handling and analysis process and they therefore include deficiencies in analytical procedures. It is important to be able to separate sources of imprecision attributable to field vs. lab practices. Using multiple forms of replication can help to isolate sources of variation.

Lab replicates are useful in assessing the precision of analytical procedures. Lab replication entails analyzing multiple subsamples from a single sample. The originating sample is reasonably assumed to be homogenous, and thus the generated data are expected to be identical if the analytical procedure is implemented consistently. Lab replicates therefore evaluate consistency in sample preparation and analysis, and are an important complement to field replicates.

Replicate performance for a set of two samples can be calculated as the relative percent difference (RPD) between two replicates, R1 and R2, as 

$RPD = (|R_1 - R_2|)/((R_1+R_2)/2) \cdot 100$

<!-- $$ RPD = {|R1-R2| \over (R1 + R2)/2} \cdot 100 $$ -->

When a set of replicates has more than two samples, performance can be calculated as the coefficient of variation (CV), where $\sigma$ is the standard deviation and $\mu$ is the mean of the replicates:

$CV = \sigma / \mu \cdot 100$

<!-- $$ CV = {\sigma \over \mu} \cdot 100 $$  -->

Replicate performance targets are typically 20% or lower. If replicates are more variable than a project's target, performance may be able to be improved by conducting sampling or laboratory activities more systematically and consistently. Guidance on replication rates are typically to collect one field replicate for every ten samples or at least one field replicate per sampling day, whichever results in greater replication. The one-per-ten guideline is also commonly used for laboratory replicates. Aside from these general guidelines, precision targets and replication rates should be a function of project characteristics. Projects that are controversial, costly, high-profile, or otherwise consequential for human or environmental health require high-quality data and may necessitate elevated rates of replication.

Replicate data in WQP present challenges for analyses of their performance. WQP data identify paired lab replicates clearly, but field replicates are ambiguous. For field replicates, one WQP entry is labeled as a replicate but the corresponding paired sample is not identified. To make these identifications, the analysis conducted for this report identified replicate sets as groups of samples collected at the same location (monitoring site ID), depth, and on the same day. After identifying sets of replicated data, lab replicates were separated by identifying sets with a sample type including the text 'Quality Control Sample-Lab Duplicate.' Simultaneously collected samples were treated as field replicates unless they were labeled as lab replicates or otherwise differentiated. 

There are potential flaws in this approach to designating replicates; for example, data erroneously input twice or collected as part of an intra-day intensive time series would be treated as field replicates. These scenarios would artificially inflate replicate collection rates and have an unpredictable effect on replicate variability. Project staff are encouraged to evaluate the raw data independently and carefully before acting on the recommendations below.


### Summary of Replicate Data


```{r}
#| echo: false
#| warning: false
#| message: false

### which of these year-parameter combos have reps collected?
repDat                 <- allSummary$rep_proc
repDat$year            <- as.numeric(substr(repDat$ActivityStartDate, 1, 4))
param_yrs_wo_reps <- plyr::ddply(repDat[, c('CharacteristicName', 'aver', 'year')], 
                         c('CharacteristicName', 'year'), plyr::summarise, 
                         number_of_reps       = sum(!is.na(aver)))
tmpDat        <- allSummary$data
tmpDat$year   <- as.numeric(substr(tmpDat$ActivityStartDate, 1, 4))
reps_expected <- plyr::ddply(tmpDat[, c('CharacteristicName', 'ResultMeasureValue', 'year')], 
                         c('CharacteristicName', 'year'), plyr::summarise, 
                         number_of_obs       = sum(!is.na(ResultMeasureValue)))
reps_expected <- plyr::join_all(list(reps_expected, param_yrs_wo_reps))
reps_expected$number_of_reps[is.na(reps_expected$number_of_reps)] <- 0
reps_expected$ratio <- reps_expected$number_of_reps / reps_expected$number_of_obs * 100
reps_expected$`Collection rate target met?` <- ifelse(reps_expected$ratio < 10, 'No', 'Yes')

rep_ratio_plot <- ggplot(data = reps_expected[!is.na(reps_expected$ratio), ], aes(x = year, y = ratio)) + 
  geom_point(aes(fill = `Collection rate target met?`), pch = 21, size = 3)+ 
  scale_x_continuous(breaks = seq(1800, 2500, 1), minor_breaks = seq(1800, 2500, 1)) + #, guide = guide_axis(n.dodge = 2)) + 
  scale_fill_manual(values = c("red", "green")) + theme_bw() + facet_wrap(. ~ CharacteristicName, scales = 'free_y') + geom_hline(yintercept = 10, linetype = 2) +
  scale_y_continuous(labels = function(x) paste0(x, "%"))  + ylab('Field replicate collection rate') + xlab('') + geom_line(linetype = 3, col = 'gray60') + theme(legend.position='bottom') + theme(axis.text.x=element_text(size=rel(0.75)))

### is there a trend in blank collection rates over time:
rep_lm    <- summary(lm(ratio ~ year, data = reps_expected[is.finite(reps_expected$ratio), ]))
rep_rsq   <- rep_lm$r.squared # r2 for time variable
rep_pval  <- rep_lm$coefficients[8] # p-value for time variable
rep_slope <- rep_lm$coefficients[2] # slope over time

if (is.na(rep_pval)) {
  rep_collection_trend_message <- ''
} else if (rep_pval > 0.05) {
  rep_collection_trend_message <- paste0('Across all available parameters (Fig. X), field replicate collection frequencies do not show any trend over time (linear model; P>0.05).')
} else if (rep_pval < 0.05) {
  rep_collection_trend_message <- paste0('Across all available parameters, field replicate collection frequencies show a significant ', ifelse(rep_slope < 0, "downward", "upward"), ' trend over time (linear model; P<0.05, r^2^ = ', round(rep_rsq, 2), ').')
  if (rep_slope < 0) {
    rep_collection_trend_message <- paste0(rep_collection_trend_message, ' Declining field replicate collection rates are deeply concerning. The project should immediately raise replicate collection rates to at least 10% of the samples collected in each sampling event. Figure 5 can be used to identify parameters requiring more replication (those appearing as red points).')
  }
   if (rep_slope > 0) {
    rep_collection_trend_message <- paste0(rep_collection_trend_message, ' Rising field replicate collection rates are very encouraging and the effort directed at this quality control metric is commended.')
   }
}
```


```{r}
#| echo: false
#| warning: false
#| message: false

### Replicate sets above 20% variation, by parameter
### can split this into field vs. lab in future if orgs report lab reps
above20_by_param <- plyr::ddply(allSummary$rep_proc, c('CharacteristicName', 'ActivityTypeCode'), plyr::summarize,
      `Number of replicate sets`       = sum(!is.na(RPD)),
      `Sets with variation above 20%` = sum(RPD > 20, na.rm = TRUE),
      `Proportion above 20%`     = paste0(round(100*(sum(RPD > 20, na.rm = TRUE) / sum(!is.na(RPD)))), '%')
      )
above20_by_param$`Sample Type` <- above20_by_param$ActivityTypeCode
# Lab Duplicate
analytes_reps    <- tot_samples$CharacteristicName
if (length(analytes_reps) == 0) {
    ### table should still exist if no non-sonde data is collected
    analytes_reps    <- NA
}

fillout_params <- expand.grid('Sample Type' = c('Field replicate', 'Lab duplicate'), 
                                  'CharacteristicName' = analytes_reps)
### This ensures field params aren't expected to have lab reps
setA <- grep(x = fillout_params$`Sample Type`, pattern = 'Lab')
setB <- which(fillout_params$CharacteristicName %in% sonde_parameters)
fillout_params <- fillout_params[-c(intersect(setA, setB)), ]

above20_by_param <- plyr::join_all(list(fillout_params, above20_by_param[, c(1, 3:ncol(above20_by_param))]), by = c('Sample Type', 'CharacteristicName'), type = 'full')
above20_by_param$`Number of replicate sets`[is.na(above20_by_param$`Number of replicate sets`)] <- 0
above20_by_param <- above20_by_param[order(above20_by_param$`Sample Type`),]

if (any(!is.na(allSummary$rep_proc$RPD))) {
### consider adding 95% CIs (notch = TRUE looks bad): https://stackoverflow.com/a/22200586
### TODO: annotate with total number from 
rep_totals_by_param <- data.frame(table(allSummary$rep_proc$CharacteristicName))
rep_totals_by_param$tot_samples <- tot_samples$`Total observations`[tot_samples$CharacteristicName %in% as.character(rep_totals_by_param$Var1)]
rep_totals_by_param$label_text <- paste0(as.character(rep_totals_by_param$Freq))#, 
                                         # '\n', round(rep_totals_by_param$Freq/ rep_totals_by_param$tot_samples * 100), '%')
rep_totals_by_param$label_text[1] <- paste0('n = ', rep_totals_by_param$label_text[1])

label_location <- as.numeric(quantile(x = allSummary$rep_proc$RPD, probs = 0.95, na.rm = TRUE))

fig3 <- ggplot(allSummary$rep_proc[grepl(x = allSummary$rep_proc$ActivityTypeCode, pattern = 'Field replicate'), ], aes(x = CharacteristicName, y = RPD)) +
  geom_boxplot(outlier.shape = NA) + theme_bw() + #  theme(axis.text.x=element_blank())
  ylab(paste0(allSummary$rep_summary$variation_measure[1], ' (field replicates)')) + xlab('') + scale_y_continuous(labels = function(x) paste0(x, "%")) +  
  geom_jitter(width=0.2, size=2, alpha = 0.2) +
  geom_text(
    data = rep_totals_by_param,
    aes(x = Var1, y = label_location,label = label_text),
    vjust = -0.5,
    size = 4,
    stat = "identity"
  ) +
  geom_hline(yintercept = 20, linetype = 2)

above20_by_param$tot_samples               <- tot_samples$`Total observations`[match(above20_by_param$CharacteristicName, tot_samples$CharacteristicName)]
above20_by_param$rep_freq                  <- above20_by_param$`Number of replicate sets`/ above20_by_param$tot_samples * 100
above20_by_param$`Replicate collection rate (%)` <- paste0(round(above20_by_param$rep_freq, 1), '%')
above20_by_param$`Replicates >10% of samples?`        <- ifelse(above20_by_param$rep_freq >= 10.0, "\u2705", "\u274C")
above20_by_param$`Are <10% of replicates high-variation?` <- ifelse(above20_by_param$`Proportion above 20%` <= 10.0, "\u2705", "\u274C")
} else {
  fig3 <- ggplot() + ggtitle('No replicates reported')
  above20_by_param$tot_samples                     <- NA
  above20_by_param$rep_freq                        <- NA
  above20_by_param$`Replicate Collection rate (%)` <- NA
  above20_by_param$`Are replicates >10% of samples?`        <- "\u274C"
  above20_by_param$`Are <10% of replicates high-variation?` <- "\u274C"
}
names(above20_by_param)[grep(x = names(above20_by_param), pattern = 'CharacteristicName')] <- 'Analyte'

table2 <- above20_by_param[!is.na(above20_by_param$Analyte), c(1:4, 8, 5, 9, 10)] # c(1:3, 7, 4, 8:9)]
if (field_only) {
  table2 <- table2[grep(x = table2$`Sample Type`, pattern = 'Field'), ]
}

### number of field and lab reps
total_reps <- sum(allSummary$rep_summary$n, na.rm = TRUE)
number_of_field_reps <- sum(allSummary$rep_summary$n[grep(x = allSummary$rep_summary$ActivityTypeCode, pattern = 'Field')], na.rm = TRUE)
number_of_lab_reps   <- sum(allSummary$rep_summary$n[grep(x = allSummary$rep_summary$ActivityTypeCode, pattern = 'Lab')], na.rm = TRUE)
samples_for_rep_comparison <- sum(!is.na(allSummary$data$ResultMeasureValue[allSummary$data$CharacteristicName %in% allSummary$rep_summary$CharacteristicName])) # only use params that have field or lab reps



### identify years without reps
### can make this more complex, identifying params without blank data in years when other params had reported blank data
years_with_reps    <- as.numeric(unique(allSummary$rep_summary$year))
years_with_data    <- as.numeric(na.omit(unique(substr(allSummary$data$ActivityStartDateTime, 1, 4))))
years_without_reps <- years_with_data[!(years_with_data %in% years_with_reps)]

if(length(years_without_reps) < 1) {
 year_rep_message <- 'Replicate data was reported in every year during the period of record covered by this report.' 
} else {
  year_rep_message <- paste0('Replicate data was completely missing from ', sub(",([^,]*)$",", and\\1", x = paste0(years_without_reps, collapse = ', ')),'.')
}

### identify the three params with the highest variation
median_vals <- plyr::ddply(allSummary$rep_proc, c('CharacteristicName'), plyr::summarize, 
                           medianRPD = median(RPD, na.rm = TRUE)
                           )
highest_variation_params <- median_vals[order(median_vals$medianRPD, decreasing = TRUE), ][1:3, ]
median_variation_above20 <- median_vals$CharacteristicName[median_vals$medianRPD > 20]

total_reps_above20      <- sum(allSummary$rep_proc$RPD > 20, na.rm = TRUE)
reps_pct_above20        <- round(total_reps_above20 / sum(!is.na(allSummary$rep_proc$RPD)) * 100)
summary_reps_above20    <- paste0(total_reps_above20, ' sets of replicates (', reps_pct_above20, '% of the total) had a ', tolower(allSummary$rep_summary$variation_measure[1]), ' exceeding the target 20%.')

variation_measure_message <- ifelse(allSummary$rep_summary$variation_measure[1] == "Coefficient of Variation", 
                                    paste0('Some replicates sets included as many as ', max(table(allSummary$rep_raw$id)), ' individual replicates. This could indicate errors during data entry into WQP, or it may reflect exceptional levels of replication. This report could not resolve those uncertainties, and so used the coefficent of variation (CV) as the measure of variation among replicates. Lower CVs indicate less variation among replicates.'), 
                                    'Replicate sets contained a maximum of two individual samples, and so the relative percent difference (RPD) was used as the measure of variation among replicates. Lower RPDs indicate lower levels of variation among replicates.')



### parameters-years without reps (even sonde data should be replicated)
if (any(reps_expected$number_of_reps == 0)) {
  # year_rep_message
  tst_rep <- reps_expected[which(reps_expected$number_of_reps == 0), c('CharacteristicName', 'year')]
  fragments_rep <- apply(X = tst_rep, MARGIN = 1, FUN = paste0, collapse = ' in ')
  fragments_rep <- sub(",([^,]*)$",", and\\1", x = paste0(fragments_rep, collapse = ', '))
  year_rep_message <- paste0(year_rep_message, " ", sum(reps_expected$number_of_reps == 0), ' parameter-years had lab data without corresponding field replicate data (', fragments_rep, '; see points with 0% collection rates in Figure 5). Quality control measures should always be collected when samples are collected.')
} else {
  ' Although not every lab parameter may be measured every year, every parameter-year combination that had data reported for this project also had some replicate data reported.'
}
# 
parameters_without_reps <- unique(allSummary$data$CharacteristicName)[!(unique(allSummary$data$CharacteristicName) %in% c(unique(allSummary$rep_summary$CharacteristicName)))]
# 
# if(length(parameters_without_reps) < 1) {
#  parameter_rep_message <- 'All of the parameters included in this report had some replicate data.'
# } else {
#   parameter_rep_message <- paste0('Parameters without replicates included ', paste0(parameters_without_reps, collapse = ', '),'.')
# }

TN_note <- NULL
### add a note if TN is a calculated quantity
if (('TN' %in% parameters_without_reps) && (unique(allSummary$data[allSummary$data$CharacteristicName == 'TN', 'ResultAnalyticalMethod.MethodIdentifier']) == 'Calculated')) {
  TN_note <- 'Although TN is identified as a calculated parameter in this study, replicate values should be calculated and reported in WQP. Replicates can be calculated using replicate data for the component compounds (TKN-N, NH3-N, NO3+NO2-N).'
}

```

Over the period of record used for this report, `r allSummary$data$OrganizationFormalName[1]` collected `r total_reps` sets of replicates. This combined total includes `r number_of_field_reps` field replicates and `r number_of_lab_reps` lab replicates. Field replicates amounted to `r round(number_of_field_reps/ samples_for_rep_comparison*100, 1)`% of all samples.

`r variation_measure_message`

In comparison to the 20% target level of variation, replicate performance was `r ifelse(reps_pct_above20 <= 10, 'excellent', ifelse(reps_pct_above20 <= 25, 'decent', ifelse(reps_pct_above20 <= 50, 'not good', ifelse(reps_pct_above20 > 50, 'poor'))))`. `r summary_reps_above20`

`r year_rep_message`


`r rep_collection_trend_message`

Replicate variation is expected to be elevated for analytes that are not homogenous throughout the water column. This group includes *E. coli*, turbidity/total suspended solids (TSS), total Kjeldahl nitrogen (TKN), total phosphorus, and other analytes that rely on particulate fractions. This variation itself may be inconsistent over time (Figure 7), varying as a function of discharge and local in-stream deposition/erosion dynamics.

Analytes that measure dissolved quantities (temperature, DO, ions) are expected to be more consistent between replicate samples, and variation in these analytes is more likely to reflect discrepancies in sample collection, handling, and contamination. However, if dissolved analytes (NO3-N, NH3-N) are filtered in the lab rather than in the field, there are opportunities for compounds to sorb or desorb from particles in the collected water, providing another source of variation captured by replicates.

```{r}
#| echo: false
#| warning: false
#| fig-width: 8
#| fig-cap: Figure 5. Field replicate collection rates for each parameter and year. Point color indicates a comparison with this report's replicate collection rate target of 10% of relevant samples (dashed horizontal line). Parameter-years with less than the target 10% collection rate are shown in red; parameter-years satisfying the 10% target are shown in green. Note that y-axis range varies among facets.
rep_ratio_plot
```


```{r}
#| echo: false
#| warning: false
#| fig-width: 8
#| fig-cap: Figure 6. Field replicate performance by parameter during the period of record for this report. Each point shows variation among a set of simultaneously-collected replicates, overlaid on boxplots indicating the 25th, 50th (bar), and 75th percentiles of the distribution for each parameter. Boxplot whiskers extend to the largest value up to 1.5 times the interquartile range beyond the 25th and 75th percentiles. The total number of field replicate sets are indicated above each parameter. A dashed horizontal line is shown at the 20% level for reference.


fig3
```



```{r}
#| echo: false
#| warning: false
#| fig-width: 8
#| fig-cap: Figure 7. Field replicate performance over time for each parameter, compared with this report's target of less than 20% variation (dashed horizontal line). Replicates with less than 20% variation satisfy this report's performance target and are shown as green points. Replicates exceeding this report's 20% variation target are shown in red. Note that y-axis range varies among facets.
if (!any(complete.cases(allSummary$rep_proc))) {
  ggplot() + ggtitle('No replicates reported')
} else {
allSummary$rep_proc$date <- as.POSIXct(sapply(X = strsplit(allSummary$rep_proc$id, '__'), FUN = '[[', 6), format = '%Y-%m-%d')

field_rep_plot_data <- allSummary$rep_proc[grepl(x = allSummary$rep_proc$ActivityTypeCode, pattern = 'Field replicate'), ]
# field_rep_plot_data <- field_rep_plot_data[!is.na(field_rep_plot_data$RPD), ]
field_rep_plot_data$`Performance target met?` <- ifelse(field_rep_plot_data$RPD > 20, 'No', 'Yes')
field_rep_plot_data$`Performance target met?`[is.na(field_rep_plot_data$`Performance target met?`)] <- 'NA'
field_rep_plot_data$`Performance target met?` <- ordered(x = field_rep_plot_data$`Performance target met?`, levels = c('No', 'Yes', 'NA'))


### issue: code doesn't interpret ResultDetectionConditionText == 'Present Above Quantification Limit' - these appear as NAs
### for SRST: 
# tmp <- allSummary$rep_raw[grepl(x = allSummary$rep_raw$ActivityStartDate, pattern = '2016-08-11|2017-08-10'), ]
# tmp2 <- tmp[grepl(x = tmp$MonitoringLocationIdentifier, pattern = 'SRSTEPA-SW-GR-2016-03|SRSTEPA-SW-GR-460-01'), ]
# tmp2[tmp2$CharacteristicName %in% 'E_coli', ] # $ResultMeasureValue

# rep_plot1 <- ggplot(allSummary$rep_proc[grepl(x = allSummary$rep_proc$ActivityTypeCode, pattern = 'Field replicate'), ], aes(x = date, y = RPD)) +
#   geom_line(linetype = 2) + geom_point() + scale_y_continuous(labels = function(x) paste0(x, "%")) +
#   facet_wrap(. ~ CharacteristicName, scales = 'free_y') + theme_bw() +
#   geom_hline(yintercept = 20, linetype = 3) +
#   labs(y = paste0(allSummary$rep_summary$variation_measure[1], ' (field replicates)'), x = '') # '(\u00b11SD)'
rep_plot <- ggplot(field_rep_plot_data, aes(x = date, y = RPD)) +
  geom_line(linetype = 2) + 
  geom_point(aes(fill = `Performance target met?`), pch = 21, size = 3) + scale_fill_manual(values = c("red", "green", 'gray')) +
  theme_bw() + facet_wrap(. ~ CharacteristicName, scales = 'free_y') + theme_bw() + theme(plot.margin = margin(r = 40, unit = "pt")) +
   geom_hline(yintercept = 20, linetype = 3) +
  labs(y =  paste0(allSummary$rep_summary$variation_measure[1], ' (field replicates)'), x = '') + theme(legend.position='bottom')

rep_plot
}

```



```{r}
#| echo: false
#| warning: false
#| label: Table2
#| fig-cap: Table 2. Summary of replicate collection rates and performance over the entire period of record covered by this report. The rightmost two columns assess whether the project's collection rates and replicate performance meet target criteria (green checks) or not (red 'X' marks).
gt::tab_options(gt::gt(table2), table.font.size = 11)
# knitr::kable(table2, row.names = FALSE)
```



### Recommendations

```{r}
#| include: false
### recommendations based on replicate data 
if (number_of_lab_reps == 0) {
  lab_rep_rec <- '**Laboratory replicates** were not present in data found in the Water Quality Portal. These data appear to have been either not collected or not input into WQP. More comprehensive reporting of laboratory replicates into WQP would enable more meaningful assessment of data quality. Project staff are encouraged to ensure lab data are entered into WQP. Including lab replicate performance in project progress reports is recommended as an effective way to track improvements in this quality metric.'
} else if (number_of_lab_reps < 0.10*samples_for_rep_comparison) {
  lab_rep_rec <- paste0('**Laboratory replicates** appear in the data reported to WQP, but represent just ', round(number_of_lab_reps / samples_for_rep_comparison*100), '% of all samples. Recommendations include ensuring that laboratory replicates are reported comprehensively and increasing laboratory replicate rates to at least 10% of lab samples. Including lab replicate performance in project progress reports is recommended as an effective way to track improvements in this quality metric.')
} else if (number_of_lab_reps >= 0.10*samples_for_rep_comparison) {
  lab_rep_rec <- '**Laboratory replicates** represent at least 10% of all lab samples. Project Managers are commended for their high level of effort and reporting on this quality metric.'
}
rec_list$lab_rep <- lab_rep_rec


### field reps
if (number_of_field_reps == 0) {
  field_rep_rec <- '**Field replicates** were either not collected or not input into WQP. More comprehensive reporting of field replicates in WQX is critical for evaluating contamination and bias in the generated data. Improving collection and reporting of field replicate data is critical to ensure that project data can be inform decision-making. Including replicate collection rates for each parameter in project progress reports would be an effective way to track improvement in this metric.'
} else if (number_of_field_reps < 0.10*samples_for_rep_comparison) {
  field_rep_rec <- paste0('**Field replicates** appear in the data reported to WQP at a rate of ', round(number_of_field_reps / samples_for_rep_comparison*100), '% of all samples. Recommendations include ensuring that field replicates are reported comprehensively and increasing field replicate collection rates to at least 10% of the data for each parameter. Including field replicate collection rates for each parameter in project progress reports would be an effective way to track improvement in this metric.')
}else if (number_of_field_reps >= 0.10*samples_for_rep_comparison) {
  field_rep_rec <- paste0("**Field replicates** represent ", round(number_of_field_reps / samples_for_rep_comparison*100), "% of all samples (excluding sonde data), satisfying this report's target level of 10%. Project Managers are commended for their high level of effort and reporting on this quality metric.")
}
rec_list$field_rep <- field_rep_rec

### Inconsistent rep collection (over time and among parameters)
# if ((length(years_without_reps) == 0)) {
#   rep_collection_consistency_time <- '**Replicate collection over time:** Replicates were collected and reported in every year, which merits recognition. '
# } else if ((length(years_without_reps) > 0)) {
#   rep_collection_consistency_time <- '**Replicate collection over time:** Replicates were reported inconsistently over time, with some years having no replicates reported. '
# }
# if ((length(parameters_without_reps) == 0)) {
#   rep_collection_consistency_param <- '**Replicate collection by parameter:** Evaluating consistency in replicate reporting across parameters, it is observed that the reported data include at least one replicate for every laboratory analyte. Project managers should ensure that this comprehensive level of quality control data continues.'
# } else if ((length(parameters_without_reps) > 0)) {
#   rep_collection_consistency_param <- paste0('**Replicate collection by parameter:** Replicates were not reported consistently across parameters, with some analytes having no replicate data found in the Water Quality Portal. Project managers should ensure that every analyte has field and lab replicate data reported for every year in which that analyte is measured. ', parameter_rep_message)
# }

### Inconsistent rep collection (over time and among parameters)
if (length(apply(X = tst_rep, MARGIN = 1, FUN = paste0, collapse = ' in ')) > 0) {
  rep_collection_consistency_time <- paste0('**Field replicate coverage:** Field blank data were collected inconsistently and were not present for all parameters in every year. Notably, ', length(apply(X = tst_rep, MARGIN = 1, FUN = paste0, collapse = ' in ')), ' parameter-years lacked any field replicates. Replicates should be collected at least once per 10 samples for every parameter. Documenting replicate collection rates in project progress reports is recommended as a way to track and improve coverage.')
} else {
  rep_collection_consistency_time <- paste0("**Field replicate coverage:** Field replicate data were collected very consistently, including at least some replicates for every parameters in every year. Although there may be room for improvement to hit the taget 10% rate for all parameters, the presence of these data commendable and demonstrates the project staff's strong commitment to quality control.")
}

### replicate performance and possible sample handling issues
if(is.na(reps_pct_above20)) {
  rep_issues <- paste0('Replicates were not reported, and thus it is not possible to evaluate replicate performance or the quality of the ', allSummary$data$OrganizationFormalName[1], ' data appearing in WQP.')
} else if(reps_pct_above20 <= 10) {
  rep_issues <- 'This is encouraging and suggests consistency and attention to detail during sample collection and handling. See Table 2 and Figure 6 for parameter-specific performance and to identify specific areas for improvement.'
} else {
  rep_issues <- 'This level of imprecision suggests examining opportunities for improved consistency and attention to detail during sample collection and handling. Increasing the rate of replicate collection is recommended to help identify the underlying issues. See Table 2 and Figure 7 for parameter-specific performance and to identify specific parameters to target for improvement.'
}


rec_list$rep_freq_time  <- rep_collection_consistency_time
# rec_list$rep_freq_param <- rep_collection_consistency_param
rec_list$rep_issues     <- paste0('**Field replicate performance:** Overall, ', reps_pct_above20, '% of replicates had problematic levels of imprecision. ' , rep_issues)

```

-   `r rec_list$lab_rep`

-   `r rec_list$field_rep`

-   `r rec_list$rep_freq_time` `r if(!is.null(TN_note)) TN_note`

-   `r rec_list$rep_issues`





::: {.content-hidden when-format="docx"}

## Supporting data

The following files contain the data used in this report:

```{r}
#| echo: false
#| warning: false
blank_file <- tempfile(fileext = '.csv')
blank_data <- write.csv(allSummary$blank_proc, file = blank_file, row.names = FALSE)
appendToFileName <- paste0("_", allSummary$data$OrganizationIdentifier[1], "_", min(years_with_data, na.rm = TRUE), "_", max(years_with_data, na.rm = TRUE))
### can we avoid using downloadthis package?
downloadthis::download_file(path = blank_file,
  output_name  = paste0("Blank_data_raw", appendToFileName),
  button_label = "Download blank data", 
  button_type  = "default",
  has_icon     = TRUE,
  icon         = "fa fa-save"
  )
```

\n 

```{r}
#| echo: false
#| warning: false
blank_summary_file <- tempfile(fileext = '.csv')
blank_summary_data <- write.csv(allSummary$blank_summary, file = blank_summary_file, row.names = FALSE)
downloadthis::download_file(path = blank_summary_file,
  output_name  = paste0("Blank_data_summary", appendToFileName),
  button_label = "Download blank data (annual summary)",
  button_type  = "default",
  has_icon     = TRUE,
  icon         = "fa fa-save"
  )
```

```{r}
#| echo: false
#| warning: false
rep_file <- tempfile(fileext = '.csv')
rep_data <- write.csv(allSummary$rep_raw, file = rep_file, row.names = FALSE)
downloadthis::download_file(path = rep_file,
  output_name  = paste0("Replicate_data_raw", appendToFileName),
  button_label = "Download replicate data (raw)",
  button_type  = "default",
  has_icon     = TRUE,
  icon         = "fa fa-save"
  )
```
    
    
```{r}
#| echo: false
#| warning: false
rep_file2 <- tempfile(fileext = '.csv')
rep_data2 <- write.csv(allSummary$rep_proc, file = rep_file2, row.names = FALSE)
downloadthis::download_file(path = rep_file2,
  output_name  = paste0("Replicate_data_processed", appendToFileName),
  button_label = "Download replicate data (processed)",
  button_type  = "default",
  has_icon     = TRUE,
  icon         = "fa fa-save"
  )
```
    
```{r}
#| echo: false
#| warning: false
rep_summary_file <- tempfile(fileext = '.csv')
rep_summary_data <- write.csv(allSummary$rep_summary, file = rep_summary_file, row.names = FALSE)
downloadthis::download_file(path = rep_summary_file,
  output_name  = paste0("Replicate_data_summary", appendToFileName),
  button_label = "Download replicate data (annual summary)",
  button_type  = "default",
  has_icon     = TRUE,
  icon         = "fa fa-save"
  )
```


```{r}
#| echo: false
#| warning: false
data_file <- tempfile(fileext = '.csv')
data_summary_data <- write.csv(allSummary$data, file = data_file, row.names = FALSE)
downloadthis::download_file(path = data_file,
  output_name  = paste0("Processed_data", appendToFileName),
  button_label = "Download post-QC data",
  button_type  = "default",
  has_icon     = TRUE,
  icon         = "fa fa-save"
  )
```


```{r}
#| echo: false
#| warning: false
raw_data_file <- tempfile(fileext = '.csv')
raw_data_summary_data <- write.csv(tribeData2[order(tribeData2$OrganizationFormalName, tribeData2$ActivityStartDate, tribeData2$MonitoringLocationIdentifier, tribeData2$CharacteristicName), ], file = raw_data_file, row.names = FALSE)
downloadthis::download_file(path = raw_data_file,
  output_name  = paste0("WQP_data", appendToFileName),
  button_label = "Download WQP data",
  button_type  = "default",
  has_icon     = TRUE,
  icon         = "fa fa-save"
  )
```

::: 
